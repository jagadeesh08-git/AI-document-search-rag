ğŸ“„ AI Document Search using RAG

An AI-powered Document Question Answering system built using Retrieval-Augmented Generation (RAG).
Upload documents and ask questions â€” answers are generated strictly from uploaded content.

This project demonstrates the practical use of:

Large Language Models (LLMs)

Vector databases

Document retrieval pipelines

Streamlit web apps

ğŸš€ Demo

Deployed on Streamlit Cloud:
https://ai-document-search-rag-85nzddooadkfysdpwyzc6a.streamlit.app/

ğŸ“¸ App Preview

Add a screenshot here later

<img width="1913" height="875" alt="image" src="https://github.com/user-attachments/assets/d5e605fa-f71a-40bc-b170-591802f9832c" />


âœ¨ Features
ğŸ“„ Multiple Document Upload

Upload PDF, TXT, and CSV files simultaneously

Documents are automatically indexed for search

ğŸ’¡ Auto Question Suggestions (Per Document)

Generates smart question suggestions for each uploaded document

Extracts keywords from document content

Helps users:

Explore documents quickly

Understand main topics

Ask meaningful questions

ğŸ” Document Question Answering

Ask questions about uploaded files

Answers generated only from retrieved document chunks

ğŸ’¬ Chat History Tracking

The app stores:

Previous questions

Generated answers

Allows users to:

Review earlier interactions

Continue document exploration

â¬‡ï¸ Download Chat History

Download entire Q&A session as a text file

Useful for notes, documentation, or research logs

ğŸ“š Sidebar Document Manager

Sidebar includes:

File upload interface

Document indexing

App controls

ğŸ§  Local LLM Inference

Runs FLAN-T5 locally

Uses HuggingFace Transformers

No external API required

ğŸ§  How It Works

The application follows a Retrieval-Augmented Generation (RAG) pipeline:

Upload documents

Extract text from files

Split text into chunks

Convert chunks into embeddings

Store embeddings in ChromaDB

Retrieve relevant chunks

Generate answer using FLAN-T5

ğŸ— Architecture
User Query
    â†“
Retriever (Chroma Vector DB)
    â†“
Relevant Document Chunks
    â†“
FLAN-T5 Language Model
    â†“
Generated Answer

ğŸ›  Tech Stack
Frontend

Streamlit

AI / NLP

Transformers (FLAN-T5)

LangChain

Vector Database

ChromaDB

Document Processing

PyPDFLoader

TextLoader

CSVLoader

Language

Python

ğŸ“¦ Installation
Clone repository
git clone https://github.com/jagadeesh08-git/AI-document-search-rag.git
cd AI-document-search-rag

Install dependencies
pip install -r requirements.txt

Run the app
streamlit run app.py

ğŸ“‚ Project Structure
ai-document-search-rag/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.toml
â””â”€â”€ README.md

ğŸ¯ Learning Objectives

This project demonstrates:

Retrieval-Augmented Generation (RAG)

Document embeddings

Vector similarity search

Prompt-based answer generation

Streamlit deployment

LangChain integration

Local LLM usage

ğŸ”® Future Improvements

Replace FakeEmbeddings with real embeddings

Add HuggingFace embedding models

Add OpenAI embedding option

Add multi-document citation references

Add conversation memory

Add authentication

Improve UI/UX

Deploy with GPU inference
