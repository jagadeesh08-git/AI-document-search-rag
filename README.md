ğŸ“„ AI Document Search using RAG

An AI-powered Document Question Answering system built using Retrieval-Augmented Generation (RAG).
Upload documents and ask questions â€” answers are generated strictly from uploaded content.

This project demonstrates the practical use of:

Large Language Models (LLMs)

Vector databases

Document retrieval pipelines

Streamlit web apps

ğŸš€ Demo

Deployed on Streamlit Cloud:
https://ai-document-search-rag-85nzddooadkfysdpwyzc6a.streamlit.app/

ğŸ“¸ App Preview

Add a screenshot here later:

<img width="1913" height="875" alt="image" src="https://github.com/user-attachments/assets/f90b7d31-78e0-4b6d-bab6-6efe0e34003c" />


âœ¨ Features
ğŸ“„ Multiple Document Upload

Upload PDF, TXT, and CSV files simultaneously.
All documents are automatically indexed for search.

ğŸ’¡ Auto Question Suggestions (Per Document)

The system generates smart question suggestions for each uploaded document by extracting keywords from document content.

Helps users:

Explore documents quickly

Understand main topics

Ask meaningful questions

ğŸ” Document Question Answering

Users can ask questions about uploaded files.
Answers are generated only from retrieved document chunks.

ğŸ’¬ Chat History Tracking

The app stores:

Previous questions

Generated answers

This allows users to review earlier interactions.

â¬‡ï¸ Download Chat History

Users can download the entire session as a text file for later reference.

ğŸ“š Sidebar Document Manager

Sidebar includes:

File upload interface

Document indexing

App controls

ğŸ§  Local LLM Inference

The system runs FLAN-T5 locally using HuggingFace Transformers.

No external API required.

ğŸ§  How It Works

The application follows a Retrieval-Augmented Generation (RAG) pipeline:

Upload documents

Extract text from files

Split text into chunks

Convert chunks into embeddings

Store embeddings in ChromaDB

Retrieve relevant chunks

Generate answer using FLAN-T5

ğŸ— Architecture
User Query
    â†“
Retriever (Chroma Vector DB)
    â†“
Relevant Document Chunks
    â†“
FLAN-T5 Language Model
    â†“
Generated Answer

ğŸ›  Tech Stack
Frontend

Streamlit

AI / NLP

Transformers (FLAN-T5)

LangChain

Vector Database

ChromaDB

Document Processing

PyPDFLoader

TextLoader

CSVLoader

Language

Python

ğŸ“¦ Installation

Clone the repository:

git clone https://github.com/jagadeesh08-git/AI-document-search-rag.git
cd AI-document-search-rag


Install dependencies:

pip install -r requirements.txt


Run the app:

streamlit run app.py

ğŸ“‚ Project Structure
ai-document-search-rag/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.toml
â””â”€â”€ README.md

ğŸ¯ Learning Objectives

This project demonstrates:

Retrieval-Augmented Generation (RAG)

Document embeddings

Vector similarity search

Prompt-based answer generation

Streamlit deployment

LangChain integration

Local LLM usage

ğŸ”® Future Improvements

Replace FakeEmbeddings with real embeddings

Add HuggingFace embedding models

Add OpenAI embedding option

Add multi-document citation references

Add conversation memory

Add authentication

Improve UI/UX

Deploy with GPU inference
